{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1StJrkKlDC3",
        "outputId": "37a026ed-9319-4c1c-c1fb-6b498aad850a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric\n",
        "!pip install kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "hXFURRYOlMwg",
        "outputId": "fe9f98d9-3cf3-41db-e52b-43e4b30eb3eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4100cdc7-603b-4e28-9d7b-10a880e1fdee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4100cdc7-603b-4e28-9d7b-10a880e1fdee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ngdanhhng\",\"key\":\"930841e1d9fe3e1b76ddb6b734b5372d\"}'}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Upload kaggle api (kaggle.json)\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TES4JdylNsT"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ML5SbFlPxs",
        "outputId": "054ccc62-6512-42a1-cdfd-d17b8dc89bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/cornell-university/arxiv\n",
            "License(s): CC0-1.0\n",
            "Downloading arxiv.zip to /content\n",
            " 98% 1.49G/1.53G [00:11<00:00, 272MB/s]\n",
            "100% 1.53G/1.53G [00:11<00:00, 140MB/s]\n",
            "Archive:  arxiv.zip\n",
            "  inflating: /content/arxiv/arxiv-metadata-oai-snapshot.json  \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d cornell-university/arxiv\n",
        "!unzip arxiv.zip -d /content/arxiv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxiHn98PtP_x"
      },
      "outputs": [],
      "source": [
        "# your huggingface token\n",
        "from huggingface_hub import login\n",
        "login(\"\") \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7FpX5_qCXrD",
        "outputId": "71ac64e6-147b-4aff-a0df-bf004b7c112f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.48.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0vLUeU8N8HA",
        "outputId": "ad104ecd-85f6-47d0-e7d4-200c6fcf484d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-2718845438.py:268: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 442,368 || all params: 110,360,832 || trainable%: 0.4008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rBERT Epoch 1/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 1/43: 100%|██████████| 150/150 [04:20<00:00,  1.73s/it, loss=4.77]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 2/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 2/43: 100%|██████████| 150/150 [04:19<00:00,  1.73s/it, loss=4.45]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 3/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 3/43: 100%|██████████| 150/150 [04:49<00:00,  1.93s/it, loss=3.64]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 4/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 4/43: 100%|██████████| 150/150 [04:23<00:00,  1.75s/it, loss=2.98]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 5/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 5/43: 100%|██████████| 150/150 [04:22<00:00,  1.75s/it, loss=2.93]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 6/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 6/43: 100%|██████████| 150/150 [04:21<00:00,  1.75s/it, loss=2.31]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 7/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 7/43: 100%|██████████| 150/150 [04:20<00:00,  1.74s/it, loss=1.95]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 8/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 8/43: 100%|██████████| 150/150 [04:20<00:00,  1.74s/it, loss=1.96]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 9/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 9/43: 100%|██████████| 150/150 [04:16<00:00,  1.71s/it, loss=1.63]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 10/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 10/43: 100%|██████████| 150/150 [04:18<00:00,  1.72s/it, loss=2.03]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 11/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 11/43: 100%|██████████| 150/150 [04:20<00:00,  1.74s/it, loss=1.1]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 12/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 12/43: 100%|██████████| 150/150 [04:21<00:00,  1.74s/it, loss=1.69]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 13/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 13/43: 100%|██████████| 150/150 [04:21<00:00,  1.74s/it, loss=1.03]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 14/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 14/43: 100%|██████████| 150/150 [04:20<00:00,  1.73s/it, loss=1.53]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 15/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 15/43: 100%|██████████| 150/150 [04:18<00:00,  1.73s/it, loss=1.59]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 16/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 16/43: 100%|██████████| 150/150 [04:19<00:00,  1.73s/it, loss=1.09]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 17/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 17/43: 100%|██████████| 150/150 [04:18<00:00,  1.72s/it, loss=0.884]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 18/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 18/43: 100%|██████████| 150/150 [04:19<00:00,  1.73s/it, loss=1.24]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 19/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 19/43: 100%|██████████| 150/150 [04:19<00:00,  1.73s/it, loss=1.47]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 20/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 20/43: 100%|██████████| 150/150 [04:19<00:00,  1.73s/it, loss=1.12]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 21/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 21/43: 100%|██████████| 150/150 [04:17<00:00,  1.72s/it, loss=1.01]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 22/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 22/43: 100%|██████████| 150/150 [04:18<00:00,  1.72s/it, loss=1.3]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 23/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 23/43: 100%|██████████| 150/150 [04:16<00:00,  1.71s/it, loss=1.07]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 24/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 24/43: 100%|██████████| 150/150 [04:13<00:00,  1.69s/it, loss=1.41]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 25/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 25/43: 100%|██████████| 150/150 [04:15<00:00,  1.70s/it, loss=1.29]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 26/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 26/43: 100%|██████████| 150/150 [04:15<00:00,  1.70s/it, loss=1.15]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 27/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 27/43: 100%|██████████| 150/150 [04:13<00:00,  1.69s/it, loss=0.95]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 28/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 28/43: 100%|██████████| 150/150 [04:14<00:00,  1.70s/it, loss=1.09]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 29/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 29/43: 100%|██████████| 150/150 [04:16<00:00,  1.71s/it, loss=1.14]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 30/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 30/43: 100%|██████████| 150/150 [04:16<00:00,  1.71s/it, loss=1.49]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 31/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 31/43: 100%|██████████| 150/150 [04:15<00:00,  1.70s/it, loss=1.25]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 32/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 32/43: 100%|██████████| 150/150 [04:16<00:00,  1.71s/it, loss=0.869]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 33/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 33/43: 100%|██████████| 150/150 [04:16<00:00,  1.71s/it, loss=1.25]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 34/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 34/43: 100%|██████████| 150/150 [04:16<00:00,  1.71s/it, loss=0.988]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 35/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 35/43: 100%|██████████| 150/150 [04:15<00:00,  1.70s/it, loss=1.03]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 36/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 36/43: 100%|██████████| 150/150 [04:14<00:00,  1.70s/it, loss=1.31]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 37/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 37/43: 100%|██████████| 150/150 [04:15<00:00,  1.70s/it, loss=1.21]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 38/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 38/43: 100%|██████████| 150/150 [04:15<00:00,  1.70s/it, loss=1.02]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 39/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 39/43: 100%|██████████| 150/150 [04:15<00:00,  1.70s/it, loss=1.13]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 40/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 40/43: 100%|██████████| 150/150 [04:15<00:00,  1.70s/it, loss=1.44]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 41/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 41/43: 100%|██████████| 150/150 [04:16<00:00,  1.71s/it, loss=1.05]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 42/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 42/43: 100%|██████████| 150/150 [04:14<00:00,  1.70s/it, loss=0.721]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "BERT Epoch 43/43:   0%|          | 0/150 [00:00<?, ?it/s]/tmp/ipython-input-2718845438.py:286: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "BERT Epoch 43/43: 100%|██████████| 150/150 [04:14<00:00,  1.70s/it, loss=1.29]\n",
            "/tmp/ipython-input-2718845438.py:316: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:359: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), amp.autocast():\n",
            "Projecting SciBERT: 100%|██████████| 187/187 [03:50<00:00,  1.23s/it]\n",
            "/tmp/ipython-input-2718845438.py:445: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler_gnn = amp.GradScaler()\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n",
            "/tmp/ipython-input-2718845438.py:451: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "                    TRAINING SUMMARY\n",
            "======================================================================\n",
            "\n",
            "SciBERT Fine-tuning (LoRA r=8)\n",
            "   Epoch  1 | Loss: 4.7560 | Val Acc: 0.0017\n",
            "   Epoch  2 | Loss: 4.6029 | Val Acc: 0.0816\n",
            "   Epoch  3 | Loss: 4.0732 | Val Acc: 0.1849\n",
            "   Epoch  4 | Loss: 3.1790 | Val Acc: 0.3931\n",
            "   Epoch  5 | Loss: 2.4890 | Val Acc: 0.4705\n",
            "   Epoch  6 | Loss: 2.0945 | Val Acc: 0.5065\n",
            "   Epoch  7 | Loss: 1.8881 | Val Acc: 0.5257\n",
            "   Epoch  8 | Loss: 1.7581 | Val Acc: 0.5479\n",
            "   Epoch  9 | Loss: 1.6575 | Val Acc: 0.5692\n",
            "   Epoch 10 | Loss: 1.5816 | Val Acc: 0.5780\n",
            "   Epoch 11 | Loss: 1.5163 | Val Acc: 0.5926\n",
            "   Epoch 12 | Loss: 1.4692 | Val Acc: 0.6035\n",
            "   Epoch 13 | Loss: 1.4205 | Val Acc: 0.6056\n",
            "   Epoch 14 | Loss: 1.3859 | Val Acc: 0.6136\n",
            "   Epoch 15 | Loss: 1.3549 | Val Acc: 0.6161\n",
            "   Epoch 16 | Loss: 1.3204 | Val Acc: 0.6211\n",
            "   Epoch 17 | Loss: 1.2932 | Val Acc: 0.6290\n",
            "   Epoch 18 | Loss: 1.2726 | Val Acc: 0.6278\n",
            "   Epoch 19 | Loss: 1.2522 | Val Acc: 0.6332\n",
            "   Epoch 20 | Loss: 1.2283 | Val Acc: 0.6399\n",
            "   Epoch 21 | Loss: 1.2131 | Val Acc: 0.6441\n",
            "   Epoch 22 | Loss: 1.1949 | Val Acc: 0.6437\n",
            "   Epoch 23 | Loss: 1.1815 | Val Acc: 0.6495\n",
            "   Epoch 24 | Loss: 1.1673 | Val Acc: 0.6483\n",
            "   Epoch 25 | Loss: 1.1585 | Val Acc: 0.6533\n",
            "   Epoch 26 | Loss: 1.1458 | Val Acc: 0.6570\n",
            "   Epoch 27 | Loss: 1.1347 | Val Acc: 0.6524\n",
            "   Epoch 28 | Loss: 1.1246 | Val Acc: 0.6596\n",
            "   Epoch 29 | Loss: 1.1172 | Val Acc: 0.6579\n",
            "   Epoch 30 | Loss: 1.1120 | Val Acc: 0.6575\n",
            "   Epoch 31 | Loss: 1.1029 | Val Acc: 0.6591\n",
            "   Epoch 32 | Loss: 1.0980 | Val Acc: 0.6604\n",
            "   Epoch 33 | Loss: 1.0921 | Val Acc: 0.6616\n",
            "   Epoch 34 | Loss: 1.0799 | Val Acc: 0.6600\n",
            "   Epoch 35 | Loss: 1.0822 | Val Acc: 0.6625\n",
            "   Epoch 36 | Loss: 1.0815 | Val Acc: 0.6616\n",
            "   Epoch 37 | Loss: 1.0748 | Val Acc: 0.6621\n",
            "   Epoch 38 | Loss: 1.0701 | Val Acc: 0.6637\n",
            "   Epoch 39 | Loss: 1.0697 | Val Acc: 0.6629\n",
            "   Epoch 40 | Loss: 1.0710 | Val Acc: 0.6633\n",
            "   Epoch 41 | Loss: 1.0640 | Val Acc: 0.6646\n",
            "   Epoch 42 | Loss: 1.0670 | Val Acc: 0.6642\n",
            "   Epoch 43 | Loss: 1.0667 | Val Acc: 0.6642\n",
            "\n",
            "GNN (GraphSAGE) on SciBERT + KNN graph\n",
            "   Epoch  1 | Loss: 5.0014 | Test Acc: 0.0280\n",
            "   Epoch  6 | Loss: 4.0736 | Test Acc: 0.0418\n",
            "   Epoch 11 | Loss: 3.4766 | Test Acc: 0.0406\n",
            "   Epoch 16 | Loss: 3.0912 | Test Acc: 0.0448\n",
            "   Epoch 21 | Loss: 2.8157 | Test Acc: 0.2865\n",
            "   Epoch 26 | Loss: 2.5940 | Test Acc: 0.3697\n",
            "   Epoch 31 | Loss: 2.4085 | Test Acc: 0.5044\n",
            "   Epoch 36 | Loss: 2.2550 | Test Acc: 0.5843\n",
            "   Epoch 41 | Loss: 2.1176 | Test Acc: 0.6550\n",
            "   Epoch 46 | Loss: 2.0039 | Test Acc: 0.6884\n",
            "   Epoch 51 | Loss: 1.8931 | Test Acc: 0.7077\n",
            "   Epoch 56 | Loss: 1.8039 | Test Acc: 0.7311\n",
            "   Epoch 61 | Loss: 1.7147 | Test Acc: 0.7537\n",
            "   Epoch 66 | Loss: 1.6417 | Test Acc: 0.7654\n",
            "   Epoch 71 | Loss: 1.5773 | Test Acc: 0.7779\n",
            "   Epoch 76 | Loss: 1.5212 | Test Acc: 0.7875\n",
            "   Epoch 81 | Loss: 1.4685 | Test Acc: 0.7992\n",
            "   Epoch 86 | Loss: 1.4258 | Test Acc: 0.8105\n",
            "   Epoch 91 | Loss: 1.3981 | Test Acc: 0.8176\n",
            "   Epoch 96 | Loss: 1.3608 | Test Acc: 0.8223\n",
            "   Epoch 101 | Loss: 1.3350 | Test Acc: 0.8248\n",
            "   Epoch 106 | Loss: 1.3114 | Test Acc: 0.8306\n",
            "   Epoch 111 | Loss: 1.2897 | Test Acc: 0.8344\n",
            "   Epoch 116 | Loss: 1.2714 | Test Acc: 0.8344\n",
            "   Epoch 121 | Loss: 1.2633 | Test Acc: 0.8381\n",
            "   Epoch 126 | Loss: 1.2425 | Test Acc: 0.8419\n",
            "   Epoch 131 | Loss: 1.2355 | Test Acc: 0.8419\n",
            "   Epoch 136 | Loss: 1.2206 | Test Acc: 0.8457\n",
            "   Epoch 141 | Loss: 1.2105 | Test Acc: 0.8436\n",
            "   Epoch 146 | Loss: 1.2048 | Test Acc: 0.8499\n",
            "   Epoch 151 | Loss: 1.1894 | Test Acc: 0.8494\n",
            "   Epoch 156 | Loss: 1.1853 | Test Acc: 0.8515\n",
            "   Epoch 161 | Loss: 1.1757 | Test Acc: 0.8515\n",
            "   Epoch 166 | Loss: 1.1680 | Test Acc: 0.8536\n",
            "   Epoch 171 | Loss: 1.1638 | Test Acc: 0.8519\n",
            "   Epoch 176 | Loss: 1.1516 | Test Acc: 0.8528\n",
            "   Epoch 181 | Loss: 1.1510 | Test Acc: 0.8536\n",
            "   Epoch 186 | Loss: 1.1472 | Test Acc: 0.8528\n",
            "   Epoch 191 | Loss: 1.1390 | Test Acc: 0.8557\n",
            "   Epoch 196 | Loss: 1.1332 | Test Acc: 0.8557\n",
            "   Epoch 201 | Loss: 1.1324 | Test Acc: 0.8557\n",
            "   Epoch 206 | Loss: 1.1220 | Test Acc: 0.8595\n",
            "   Epoch 211 | Loss: 1.1185 | Test Acc: 0.8591\n",
            "   Epoch 216 | Loss: 1.1164 | Test Acc: 0.8582\n",
            "   Epoch 221 | Loss: 1.1068 | Test Acc: 0.8586\n",
            "   Epoch 226 | Loss: 1.1068 | Test Acc: 0.8570\n",
            "   Epoch 231 | Loss: 1.1046 | Test Acc: 0.8607\n",
            "   Epoch 236 | Loss: 1.1017 | Test Acc: 0.8620\n",
            "   Epoch 241 | Loss: 1.0958 | Test Acc: 0.8599\n",
            "   Epoch 246 | Loss: 1.0897 | Test Acc: 0.8607\n",
            "   Final     | Loss: 1.0918 | Test Acc: 0.8591\n",
            "======================================================================\n",
            "\n",
            "Recommendations for \"advancements in graph neural networks for computer vision\":\n",
            "  • Multi-Dimensional Recurrent Neural Networks\n",
            "    Abstract:   Recurrent neural networks (RNNs) have proved effective at one dimensional\n",
            "sequence learning tasks, such as speech and online handwriting recognition.\n",
            "Some of the properties that...\n",
            "    Score: 0.8657\n",
            "\n",
            "  • A model for learning to segment temporal sequences, utilizing a mixture\n",
            "  of RNN experts together with adaptive variance\n",
            "    Abstract:   This paper proposes a novel learning method for a mixture of recurrent neural\n",
            "network (RNN) experts model, which can acquire the ability to generate desired\n",
            "sequences by dynamica...\n",
            "    Score: 0.8259\n",
            "\n",
            "  • Automatic Detection of Pulmonary Embolism using Computational\n",
            "  Intelligence\n",
            "    Abstract:   This article describes the implementation of a system designed to\n",
            "automatically detect the presence of pulmonary embolism in lung scans. These\n",
            "images are firstly segmented, befor...\n",
            "    Score: 0.8086\n",
            "\n",
            "  • Fuzzy Artmap and Neural Network Approach to Online Processing of Inputs\n",
            "  with Missing Values\n",
            "    Abstract:   An ensemble based approach for dealing with missing data, without predicting\n",
            "or imputing the missing values is proposed. This technique is suitable for\n",
            "online operations of neura...\n",
            "    Score: 0.7774\n",
            "\n",
            "  • The Parameter-Less Self-Organizing Map algorithm\n",
            "    Abstract:   The Parameter-Less Self-Organizing Map (PLSOM) is a new neural network\n",
            "algorithm based on the Self-Organizing Map (SOM). It eliminates the need for a\n",
            "learning rate and annealing...\n",
            "    Score: 0.7739\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# full_fixed_pipeline_colab_friendly_with_full_save.py\n",
        "# SciBERT + LoRA(r=8) + 12k samples + Colab-Free friendly\n",
        "# Full BERT-GNN hybrid for arXiv paper classification & recommendation\n",
        "# → Saves *everything* needed for a zero-training recommendation run\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import ast\n",
        "import random\n",
        "import logging\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.cuda.amp as amp\n",
        "from torch.optim import AdamW\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.utils import from_networkx, to_undirected\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =============================\n",
        "# Config\n",
        "# =============================\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "MODEL_NAME      = \"allenai/scibert_scivocab_uncased\"\n",
        "MAX_SAMPLES     = 12000\n",
        "BERT_BATCH_SIZE = 64\n",
        "GRAD_ACCUM_STEPS = 3\n",
        "EPOCHS_BERT     = 45\n",
        "EPOCHS_GNN      = 200\n",
        "BERT_LR         = 8e-5\n",
        "GNN_LR          = 5e-4\n",
        "MAX_LENGTH      = 256\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MODEL_SAVE_PATH = \"/content/models\"\n",
        "NUM_WORKERS = 0\n",
        "GNN_DIM = 128\n",
        "KNN_K   = 6\n",
        "CONT_WEIGHT = 0.0\n",
        "ACCUM_STEPS = GRAD_ACCUM_STEPS\n",
        "\n",
        "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "SAVE_TO_DRIVE = os.environ.get('SAVE_TO_DRIVE', '0') == '1'\n",
        "DRIVE_PATH = os.environ.get('DRIVE_PATH', '/content/drive/MyDrive/models')\n",
        "if SAVE_TO_DRIVE:\n",
        "    os.makedirs(DRIVE_PATH, exist_ok=True)\n",
        "\n",
        "logger.info(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# =============================\n",
        "# Utilities & Data\n",
        "# =============================\n",
        "def generate_synthetic_data(max_samples):\n",
        "    logger.warning(\"Generating synthetic data (synthetic mode).\")\n",
        "    cats = [f\"cs.CV\" if i % 5 == 0 else f\"cat.{i%20}\" for i in range(50)]\n",
        "    authors = [f\"Author_{j}\" for j in range(200)]\n",
        "    data = {\n",
        "        'id': [str(i) for i in range(max_samples)],\n",
        "        'title': [f\"Research on topic {i} in deep learning and vision\" for i in range(max_samples)],\n",
        "        'abstract': [f\"This work studies model {i}, presenting experiments and results that illustrate patterns. More descriptive text to give SciBERT something to learn.\" for i in range(max_samples)],\n",
        "        'authors_parsed': [[(random.choice(authors), \"\", \"\")] for _ in range(max_samples)],\n",
        "        'categories': [random.choice(cats) for _ in range(max_samples)],\n",
        "    }\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def safe_literal_eval(val):\n",
        "    if isinstance(val, str):\n",
        "        try:\n",
        "            return ast.literal_eval(val)\n",
        "        except Exception:\n",
        "            return []\n",
        "    return val if isinstance(val, list) else []\n",
        "\n",
        "def load_data(max_samples=MAX_SAMPLES):\n",
        "    try:\n",
        "        path = \"/content/arxiv/arxiv-metadata-oai-snapshot.json\"\n",
        "        df = pd.read_json(path, lines=True, nrows=max_samples)\n",
        "        logger.info(f\"Loaded {len(df)} rows from arXiv.\")\n",
        "    except Exception:\n",
        "        df = generate_synthetic_data(max_samples)\n",
        "\n",
        "    df.fillna({'abstract': \"No abstract\", 'title': \"No title\"}, inplace=True)\n",
        "    df['id'] = df['id'].astype(str)\n",
        "    df['text'] = df['title'] + \"\\n\\n\" + df['abstract']\n",
        "    df['authors_parsed'] = df.get('authors_parsed', pd.Series([[]]*len(df))).apply(safe_literal_eval)\n",
        "    df['authors_set'] = df['authors_parsed'].apply(lambda x: {a[0] for a in x if a})\n",
        "    df['categories'] = df['categories'].apply(lambda x: x.split() if isinstance(x, str) else (x if isinstance(x, list) else []))\n",
        "    df['label'] = df['categories'].apply(lambda x: x[0] if x else 'unknown')\n",
        "\n",
        "    keep = df['label'].value_counts()[lambda x: x >= 5].index\n",
        "    df = df[df['label'].isin(keep)].reset_index(drop=True)\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    df['label_enc'] = le.fit_transform(df['label']).astype(np.int32)\n",
        "    return df, le\n",
        "\n",
        "df, le = load_data(MAX_SAMPLES)\n",
        "num_classes = len(le.classes_)\n",
        "logger.info(f\"Num classes after filtering: {num_classes}\")\n",
        "gc.collect()\n",
        "\n",
        "# =============================\n",
        "# Graph: metadata edges\n",
        "# =============================\n",
        "def build_base_graph(df):\n",
        "    G = nx.Graph()\n",
        "    cat_papers = defaultdict(list)\n",
        "    author_papers = defaultdict(list)\n",
        "    for _, row in df.iterrows():\n",
        "        pid = row['id']\n",
        "        G.add_node(pid, text=row['text'])\n",
        "        for c in row['categories']:\n",
        "            cat_papers[c].append(pid)\n",
        "        for a in row['authors_set']:\n",
        "            author_papers[a].append(pid)\n",
        "    for papers in cat_papers.values():\n",
        "        for i in range(len(papers)):\n",
        "            for j in range(i+1, len(papers)):\n",
        "                G.add_edge(papers[i], papers[j])\n",
        "    for papers in author_papers.values():\n",
        "        for i in range(len(papers)):\n",
        "            for j in range(i+1, len(papers)):\n",
        "                G.add_edge(papers[i], papers[j])\n",
        "    logger.info(f\"Base graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "    return G\n",
        "\n",
        "G_base = build_base_graph(df)\n",
        "node_list = list(G_base.nodes())\n",
        "_df_indexed = df.set_index('id')\n",
        "_df_sel = _df_indexed.loc[[n for n in node_list if n in _df_indexed.index]]\n",
        "df_reindexed = _df_sel.reset_index()\n",
        "\n",
        "graph_data = from_networkx(G_base)\n",
        "graph_data.y = torch.tensor(df_reindexed['label_enc'].values, dtype=torch.long)\n",
        "texts = df_reindexed['text'].tolist()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# =============================\n",
        "# BERT Projector (SciBERT + LoRA r=8)\n",
        "# =============================\n",
        "class BertProjector(nn.Module):\n",
        "    def __init__(self, model_name, num_classes, proj_dim=GNN_DIM):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        hidden = getattr(self.bert.config, 'hidden_size', 768)\n",
        "        self.classifier = nn.Linear(hidden, num_classes)\n",
        "        self.projection = nn.Linear(hidden, proj_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, project=True):\n",
        "        out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last = out.last_hidden_state\n",
        "        mask = attention_mask.unsqueeze(-1).expand_as(last).float()\n",
        "        summed = (last * mask).sum(1)\n",
        "        lengths = mask.sum(1).clamp(min=1e-9)\n",
        "        pooled = summed / lengths\n",
        "        logits = self.classifier(pooled)\n",
        "        projected = self.projection(pooled) if project else pooled\n",
        "        return logits, projected\n",
        "\n",
        "lora_cfg = LoraConfig(\n",
        "    r=8, lora_alpha=16, target_modules=[\"query\", \"key\", \"value\"], lora_dropout=0.05, bias=\"none\"\n",
        ")\n",
        "\n",
        "bert_model = BertProjector(MODEL_NAME, num_classes, GNN_DIM).to(DEVICE)\n",
        "\n",
        "try:\n",
        "    bert_model.bert = get_peft_model(bert_model.bert, lora_cfg)\n",
        "except Exception as e:\n",
        "    logger.warning(f\"PEFT failed, trying fallback targets: {e}\")\n",
        "    lora_cfg = LoraConfig(r=8, lora_alpha=16, target_modules=[\"q_lin\", \"k_lin\", \"v_lin\"], lora_dropout=0.05, bias=\"none\")\n",
        "    bert_model.bert = get_peft_model(bert_model.bert, lora_cfg)\n",
        "\n",
        "try:\n",
        "    bert_model.bert.print_trainable_parameters()\n",
        "except Exception:\n",
        "    logger.info(\"(PEFT) print_trainable_parameters not available\")\n",
        "\n",
        "# =============================\n",
        "# Losses\n",
        "# =============================\n",
        "def contrastive_loss(emb, labels, margin=0.5):\n",
        "    sim = F.cosine_similarity(emb.unsqueeze(1), emb.unsqueeze(0), dim=-1)\n",
        "    label_mat = (labels.unsqueeze(1) == labels.unsqueeze(0)).float()\n",
        "    pos = label_mat * (1.0 - sim)\n",
        "    neg = (1.0 - label_mat) * torch.relu(sim - margin)\n",
        "    denom = (label_mat.sum() + (1.0 - label_mat).sum()).clamp(min=1.0)\n",
        "    return (pos.sum() + neg.sum()) / denom\n",
        "\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "    def forward(self, logits, target):\n",
        "        confidence = 1.0 - self.smoothing\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        n_classes = logits.size(-1)\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(log_probs)\n",
        "            true_dist.fill_(self.smoothing / max(1, (n_classes - 1)))\n",
        "            true_dist.scatter_(1, target.unsqueeze(1), confidence)\n",
        "        return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))\n",
        "\n",
        "# =============================\n",
        "# BERT fine-tuning\n",
        "# =============================\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts): self.texts = texts\n",
        "    def __len__(self): return len(self.texts)\n",
        "    def __getitem__(self, i): return self.texts[i]\n",
        "\n",
        "def get_scheduler_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    def lr_lambda(current_step: int):\n",
        "        if current_step < num_warmup_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps))\n",
        "        return max(0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps)))\n",
        "    return LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "def fine_tune_bert(model, texts, labels, batch_size=BERT_BATCH_SIZE, cont_weight=CONT_WEIGHT, accum_steps=ACCUM_STEPS):\n",
        "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=BERT_LR, weight_decay=1e-2, eps=1e-8)\n",
        "\n",
        "    indices = np.arange(len(texts))\n",
        "    y_np = labels.cpu().numpy()\n",
        "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=SEED, stratify=y_np) if len(np.unique(y_np))>1 else (indices, [])\n",
        "\n",
        "    total_steps = max(1, (len(train_idx) // batch_size // accum_steps) * EPOCHS_BERT)\n",
        "    warmup_steps = max(1, int(0.10 * total_steps))\n",
        "    scheduler = get_scheduler_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scaler = amp.GradScaler()\n",
        "\n",
        "    losses, accs = [], []\n",
        "    for epoch in range(EPOCHS_BERT):\n",
        "        model.train()\n",
        "        np.random.shuffle(train_idx)\n",
        "        epoch_loss = 0.0\n",
        "        batch_count = 0\n",
        "        prog = tqdm(range(0, len(train_idx), batch_size), desc=f\"BERT Epoch {epoch+1}/{EPOCHS_BERT}\")\n",
        "        for i in prog:\n",
        "            batch_idx = train_idx[i:i+batch_size]\n",
        "            batch_txt = [texts[j] for j in batch_idx]\n",
        "            batch_y = torch.tensor(y_np[batch_idx], dtype=torch.long, device=DEVICE)\n",
        "\n",
        "            enc = tokenizer(batch_txt, truncation=True, padding='max_length', max_length=MAX_LENGTH, return_tensors='pt')\n",
        "            enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
        "\n",
        "            with amp.autocast():\n",
        "                logits, proj = model(enc['input_ids'], enc['attention_mask'], project=True)\n",
        "                cls_loss = criterion(logits, batch_y)\n",
        "                cont_loss = contrastive_loss(proj, batch_y) if cont_weight > 0 else torch.tensor(0.0, device=DEVICE)\n",
        "                loss = cls_loss + cont_weight * cont_loss\n",
        "                loss = loss / accum_steps\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if ((batch_count + 1) % accum_steps) == 0 or (i + batch_size) >= len(train_idx):\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            epoch_loss += loss.item() * accum_steps\n",
        "            batch_count += 1\n",
        "            prog.set_postfix(loss=loss.item() * accum_steps)\n",
        "            del enc, logits, proj, batch_y\n",
        "            gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "        avg_loss = epoch_loss / max(1, batch_count)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "        # validation\n",
        "        model.eval()\n",
        "        all_pred, all_true = [], []\n",
        "        with torch.no_grad(), amp.autocast():\n",
        "            for i in range(0, len(val_idx), batch_size):\n",
        "                idx = val_idx[i:i+batch_size]\n",
        "                txt = [texts[j] for j in idx]\n",
        "                y = y_np[idx]\n",
        "                enc = tokenizer(txt, truncation=True, padding='max_length', max_length=MAX_LENGTH, return_tensors='pt')\n",
        "                enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
        "                logits, _ = model(enc['input_ids'], enc['attention_mask'], project=False)\n",
        "                pred = logits.argmax(dim=1).cpu().numpy()\n",
        "                all_pred.extend(pred); all_true.extend(y)\n",
        "                del enc, logits\n",
        "                gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "        acc = accuracy_score(all_true, all_pred) if all_true else 0.0\n",
        "        f1 = f1_score(all_true, all_pred, average='macro') if all_true else 0.0\n",
        "        accs.append(acc)\n",
        "        logger.info(f\"[BERT] Epoch {epoch+1} | Loss: {avg_loss:.4f} | Val Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "        # checkpoint\n",
        "        ckpt_path = os.path.join(MODEL_SAVE_PATH, f\"bert_epoch{epoch+1}.pt\")\n",
        "        torch.save(model.state_dict(), ckpt_path)\n",
        "        if SAVE_TO_DRIVE:\n",
        "            torch.save(model.state_dict(), os.path.join(DRIVE_PATH, f\"bert_epoch{epoch+1}.pt\"))\n",
        "\n",
        "    return losses, accs\n",
        "\n",
        "labels_tensor = torch.tensor(df_reindexed['label_enc'].values, dtype=torch.long, device=DEVICE)\n",
        "bert_losses, bert_accs = fine_tune_bert(bert_model, texts, labels_tensor, cont_weight=CONT_WEIGHT)\n",
        "\n",
        "# =============================\n",
        "# Projected embeddings\n",
        "# =============================\n",
        "def get_projected_embeddings(model, texts, batch_size=BERT_BATCH_SIZE, workers=NUM_WORKERS):\n",
        "    model.eval()\n",
        "    ds = TextDataset(texts)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, num_workers=workers, pin_memory=True)\n",
        "    embs = []\n",
        "    with torch.no_grad(), amp.autocast():\n",
        "        for batch in tqdm(dl, desc=\"Projecting SciBERT\"):\n",
        "            enc = tokenizer(batch, truncation=True, padding='max_length', max_length=MAX_LENGTH, return_tensors='pt')\n",
        "            enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
        "            _, proj = model(enc['input_ids'], enc['attention_mask'], project=True)\n",
        "            embs.append(proj.cpu().to(torch.float32))\n",
        "            del enc, proj\n",
        "            gc.collect(); torch.cuda.empty_cache()\n",
        "    return torch.cat(embs, dim=0) if embs else torch.zeros((0, GNN_DIM))\n",
        "\n",
        "proj_emb_cpu = get_projected_embeddings(bert_model, texts)\n",
        "proj_emb_cpu = proj_emb_cpu / (proj_emb_cpu.norm(dim=1, keepdim=True) + 1e-12)\n",
        "proj_emb_np = proj_emb_cpu.numpy()\n",
        "\n",
        "# =============================\n",
        "# Augment graph with KNN\n",
        "# =============================\n",
        "def add_knn_edges_to_graph(G, node_list, embeddings_cpu, k=KNN_K):\n",
        "    emb_np = embeddings_cpu.numpy()\n",
        "    sims = cosine_similarity(emb_np)\n",
        "    N = sims.shape[0]\n",
        "    new_edges = []\n",
        "    for i in range(N):\n",
        "        sims[i, i] = -1.0\n",
        "        kk = min(k, N-1)\n",
        "        topk = np.argpartition(-sims[i], range(kk))[:kk]\n",
        "        for j in topk:\n",
        "            new_edges.append((node_list[i], node_list[j]))\n",
        "    G_aug = G.copy()\n",
        "    before = G_aug.number_of_edges()\n",
        "    G_aug.add_edges_from(new_edges)\n",
        "    after = G_aug.number_of_edges()\n",
        "    logger.info(f\"Added {after-before} KNN edges (k={k}). Total: {after}\")\n",
        "    return G_aug\n",
        "\n",
        "G_aug = add_knn_edges_to_graph(G_base, node_list, proj_emb_cpu, k=KNN_K)\n",
        "pyg_graph = from_networkx(G_aug)\n",
        "pyg_graph.y = torch.tensor(df_reindexed['label_enc'].values, dtype=torch.long, device=DEVICE)\n",
        "edge_index = to_undirected(pyg_graph.edge_index).to(DEVICE)\n",
        "node_emb = proj_emb_cpu.to(DEVICE)\n",
        "\n",
        "# =============================\n",
        "# GNN model\n",
        "# =============================\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, in_dim, hid, n_cls, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_dim, hid)\n",
        "        self.bn1 = nn.BatchNorm1d(hid)\n",
        "        self.conv2 = SAGEConv(hid, hid)\n",
        "        self.bn2 = nn.BatchNorm1d(hid)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hid, n_cls)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, edge):\n",
        "        x = self.act(self.conv1(x, edge))\n",
        "        x = self.bn1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.act(self.conv2(x, edge))\n",
        "        x = self.bn2(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "    def embed(self, x, edge):\n",
        "        x = self.act(self.conv1(x, edge))\n",
        "        x = self.bn1(x)\n",
        "        x = self.act(self.conv2(x, edge))\n",
        "        x = self.bn2(x)\n",
        "        return x\n",
        "\n",
        "gnn = GNN(GNN_DIM, 128, num_classes, dropout=0.3).to(DEVICE)\n",
        "opt_gnn = AdamW(gnn.parameters(), lr=GNN_LR, weight_decay=1e-2)\n",
        "criterion_gnn = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
        "\n",
        "idx = np.arange(len(df_reindexed))\n",
        "y_np = pyg_graph.y.cpu().numpy()\n",
        "train_idx, test_idx = train_test_split(idx, test_size=0.2, random_state=SEED, stratify=y_np)\n",
        "train_mask = torch.zeros(len(df_reindexed), dtype=torch.bool, device=DEVICE)\n",
        "test_mask  = torch.zeros(len(df_reindexed), dtype=torch.bool, device=DEVICE)\n",
        "train_mask[torch.tensor(train_idx, dtype=torch.long, device=DEVICE)] = True\n",
        "test_mask[torch.tensor(test_idx, dtype=torch.long, device=DEVICE)] = True\n",
        "\n",
        "# =============================\n",
        "# GNN training\n",
        "# =============================\n",
        "scaler_gnn = amp.GradScaler()\n",
        "gnn_losses, gnn_accs = [], []\n",
        "\n",
        "for epoch in range(EPOCHS_GNN):\n",
        "    gnn.train()\n",
        "    opt_gnn.zero_grad()\n",
        "    with amp.autocast():\n",
        "        logits = gnn(node_emb, edge_index)\n",
        "        loss = criterion_gnn(logits[train_mask], pyg_graph.y[train_mask])\n",
        "    scaler_gnn.scale(loss).backward()\n",
        "    torch.nn.utils.clip_grad_norm_(gnn.parameters(), max_norm=1.0)\n",
        "    scaler_gnn.step(opt_gnn)\n",
        "    scaler_gnn.update()\n",
        "    gnn_losses.append(loss.item())\n",
        "\n",
        "    gnn.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = gnn(node_emb, edge_index)\n",
        "        pred = logits[test_mask].argmax(dim=1).cpu().numpy()\n",
        "        true = pyg_graph.y[test_mask].cpu().numpy()\n",
        "        acc = accuracy_score(true, pred)\n",
        "        gnn_accs.append(acc)\n",
        "\n",
        "    if epoch % 5 == 0 or epoch == EPOCHS_GNN-1:\n",
        "        logger.info(f\"[GNN] Epoch {epoch+1}/{EPOCHS_GNN} | Loss: {loss.item():.4f} | Test Acc: {acc:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt = os.path.join(MODEL_SAVE_PATH, f\"gnn_epoch{epoch+1}.pt\")\n",
        "        torch.save(gnn.state_dict(), ckpt)\n",
        "        if SAVE_TO_DRIVE:\n",
        "            torch.save(gnn.state_dict(), os.path.join(DRIVE_PATH, f\"gnn_epoch{epoch+1}.pt\"))\n",
        "\n",
        "torch.save(gnn.state_dict(), os.path.join(MODEL_SAVE_PATH, \"gnn_final.pt\"))\n",
        "if SAVE_TO_DRIVE:\n",
        "    torch.save(gnn.state_dict(), os.path.join(DRIVE_PATH, \"gnn_final.pt\"))\n",
        "\n",
        "# =============================\n",
        "# Refine embeddings & recommend\n",
        "# =============================\n",
        "gnn.eval()\n",
        "with torch.no_grad():\n",
        "    refined_emb = gnn.embed(node_emb, edge_index)\n",
        "refined_emb_np = refined_emb.cpu().numpy().astype(np.float32)\n",
        "refined_emb_np = refined_emb_np / (np.linalg.norm(refined_emb_np, axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "def recommend(query, top_k=5):\n",
        "    enc = tokenizer([query], truncation=True, padding='max_length', max_length=MAX_LENGTH, return_tensors='pt')\n",
        "    enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
        "    with torch.no_grad():\n",
        "        _, q_proj = bert_model(enc['input_ids'], enc['attention_mask'], project=True)\n",
        "        q = q_proj.cpu().numpy().astype(np.float32)\n",
        "        q = q / (np.linalg.norm(q, axis=1, keepdims=True) + 1e-12)\n",
        "    sims = cosine_similarity(q, proj_emb_np)[0]\n",
        "    top_idx = np.argsort(sims)[-top_k:][::-1]\n",
        "    return [node_list[i] for i in top_idx], sims[top_idx]\n",
        "\n",
        "def pretty_recommendation(query, ids, scores, df):\n",
        "    df_lookup = df.set_index('id')\n",
        "    lines = []\n",
        "    for pid, sc in zip(ids, scores):\n",
        "        row = df_lookup.loc[pid]\n",
        "        lines.append(f\"  • {row['title']}\\n    Abstract: {row['abstract'][:180].rstrip()}...\\n    Score: {sc:.4f}\\n\")\n",
        "    return f\"\\nRecommendations for \\\"{query}\\\":\\n\" + \"\\n\".join(lines)\n",
        "\n",
        "# =============================\n",
        "# SAVE EVERYTHING FOR PURE RECOMMENDATION\n",
        "# =============================\n",
        "save_dir = MODEL_SAVE_PATH\n",
        "\n",
        "\n",
        "df_reindexed.to_pickle(os.path.join(save_dir, \"df_reindexed.pkl\"))\n",
        "\n",
        "\n",
        "with open(os.path.join(save_dir, \"node_list.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(node_list, f)\n",
        "\n",
        "\n",
        "torch.save(proj_emb_cpu, os.path.join(save_dir, \"proj_emb_cpu.pt\"))\n",
        "\n",
        "\n",
        "torch.save({\n",
        "    \"edge_index\": edge_index.cpu(),\n",
        "    \"num_nodes\": G_aug.number_of_nodes()\n",
        "}, os.path.join(save_dir, \"graph_data.pt\"))\n",
        "\n",
        "\n",
        "torch.save(torch.from_numpy(refined_emb_np), os.path.join(save_dir, \"refined_emb.pt\"))\n",
        "\n",
        "\n",
        "with open(os.path.join(save_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "logger.info(f\"All inference artefacts saved to {save_dir}\")\n",
        "\n",
        "# =============================\n",
        "# Final Summary & Demo\n",
        "# =============================\n",
        "query = \"advancements in graph neural networks for computer vision\"\n",
        "rec_ids, rec_scores = recommend(query, top_k=5)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" \" * 20 + \"TRAINING SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nSciBERT Fine-tuning (LoRA r=8)\")\n",
        "for ep, (l, a) in enumerate(zip(bert_losses, bert_accs), 1):\n",
        "    print(f\"   Epoch {ep:2d} | Loss: {l:.4f} | Val Acc: {a:.4f}\")\n",
        "\n",
        "print(\"\\nGNN (GraphSAGE) on SciBERT + KNN graph\")\n",
        "for ep in range(0, len(gnn_losses), 5):\n",
        "    epoch = ep + 1\n",
        "    print(f\"   Epoch {epoch:2d} | Loss: {gnn_losses[ep]:.4f} | Test Acc: {gnn_accs[ep]:.4f}\")\n",
        "print(f\"   Final     | Loss: {gnn_losses[-1]:.4f} | Test Acc: {gnn_accs[-1]:.4f}\")\n",
        "print(\"=\"*70)\n",
        "print(pretty_recommendation(query, rec_ids, rec_scores, df_reindexed))\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1V4P8U0W81x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsBSco4LqrkF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hWEo0pb_Ul-"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
